Atenção:
- Não edite este ficheiro em programas como Word e afins. Use exclusivamente um editor de texto simples. Em caso de dúvida, use o editor do Spyder.
- Não altere a estrutura deste ficheiro. Preencha as respostas apenas nos espaços respectivos (a seguir à tag R#:)
- Pode adicionar linhas no espaço para as respostas mas as respostas devem ser sucintas e directas.

QUESTÔES:

Q1: Considerando os dados fornecidos, explique a necessidade de standardizar os valores dos atributos.
R1: A standarização deve ser feita quando temos grandes diferenças entre os valores dos dados, quando os dados têm diferentes unidades e quando não conhecemos bem a natureza dos dados. . Os quatro atributos dos dados fornecidos apresentam todos unidades diferentes e estalas de valores muito dispares, logo a standarização permite-nos dar a mesma importância aos dados, eliminando a influência dos fatores anteriormente descritos.


Q2: Explique como calculou os parâmetros para standardização e como os usou no conjunto de teste.
R2: Os parâmetros para a standardização (média e desvio padrão) foram calculados no conjunto de treino, e depois aplicados ao conjunto de teste. Foram calculados no conjunto de teste porque este deve ser uma amostra representativa dos dados a analisar, enquanto que o conjunto de teste pode ser uma amostra relativamente pequena.


Q3: Explique como calculou a probabilidade a priori de um exemplo pertencer a uma classe (a probabilidade antes de ter em conta os valores dos atributos do exemplo) na sua implementação do classificador Naïve Bayes. Pode incluir um trecho relevante do código se ajudar a explicar.
R3: A probabilidade a priori foi calculada no conjunto de treino e foram contados os exemplos de cada classe e dividido pelo número total de exemplos:
def apriori_probability(data):
    total = data.shape[0] # número total de exemplos
    class0 = data[data[:] == 0].shape[0] # número de exemplos da classe 0
    class1 = data[data[:] == 1].shape[0] # número de exemplos da classe 1
    return np.log(class0 / total), np.log(class1 / total)
Como na fórmula usada pelo Naive Bayes é usado o logaritmo da probabilidade a priori, é logo calculado o logaritmo deste probabilidade


Q4: Explique como o seu classificador Naïve Bayes prevê a classe a que um exemplo de teste pertence. Pode incluir um trecho relevante do código se ajudar a explicar.
R4:
Para a previsão da classe o nosso classificador Naive Bayes utiliza a fórmula:
CNaïve Bayes = argmax (k∈{0,1,...,K}) ln p(Ck) + Somatório(ln p(xj|Ck))
Então começamos por calcular o Somatório(ln p(xj|Ck)) que nos dá o somatório das probabilidade de cada atributo, sabendo a classe. Este cálculo foi feito usando o KDE.
Para casa classe foi soma da probabilidade a priori da classe com o somatório anteriormente descrito, isto para cada classe.
Ficamos assim com, para cada exemplo, a probabilidade de pertencer a cada uma das classes e é escolhida a classe com maior probabilidade.

   for c in classes:
        train_class_examples = train_set_X[train_set_Y == c]
        sum_probs = np.zeros(X.shape[0])
        for attribute in range(X.shape[1]):
            attribute_example = train_class_examples[:, [attribute]]
            kde.fit(attribute_example)  # train only with the training examples
            sum_probs += kde.score_samples(X[:, [attribute]])  # score sample for the complete set
        classes_probability[:, c] = class_apriori_prob[c] + sum_probs  # store the probabilities calculated

    predictions = np.argmax(classes_probability, axis=1)  # chooses the class with maximum probability


Q5: Explique que efeito tem o parâmetro de bandwidth no seu classificador.
R5: A bandwidth afeta quão "smooth" será a curva resultante. Mudar a bandwidth muda a forma do kernel, uma bandwidth menor significa que apenas pontos muito próximos são considerados produzindo uma curva mais irregular. Valores mais altos produzem um kernel mais achatado onde passam a ser considerados pontos mais distantes.


Q6: Explique que efeito tem o parâmetro gamma no classificador SVM.
R6: O gamma influência a curvatura da fronteira de decisão.
Valores altos de gamma fazem com que o kernel dê um maior peso a pontos mais próximos, fazendo com que a fronteira de decisão se ajuste mais rigidamente às classes. Com valores menores o ajuste é relaxado, permitindo uma fronteira mais suave.

Q7: Explique como determinou o melhor parâmetro de bandwidth e gamma para o seu classificador e o classificador SVM. Pode incluir um trecho relevante do código se ajudar a explicar.
R7: Os parâmetros foram selecionados através de cross validation. Neste processo, para cada classificador, e para cada valor do parâmetros, vamos criar 5 partições e vamos treinar o nosso classificador 5 vezes, obtendo o erro de validação obtido em cada partição. Os conjuntos usados para treino e para validação são distintos.
Utilizando o erro médio de validação é selecionado o valor do parâmetro que produziu um menor erro médio.

Q8: Explique como obteve a melhor hipótese para cada um dos classificadores depois de optimizados os parâmetros.
R8:


Q9: Mostre os melhores valores dos parâmetros optimizados, a estimativa do erro verdadeiro de cada uma das hipóteses que obteve (o seu classificador e os dois fornecidos pela biblioteca), os intervalos do número esperado de erros dados pelo teste normal aproximado e os valores dos testes de McNemar e discuta o que pode concluir daí.
R9:
Naive Bayes Classifier: Test error: 0.05934242181234964, Bandwidth: 0.32
SVM Classifier: Test error: 0.042502004811547714, Gamma: 0.6000000000000001
SVM Classifier with C: Test error: 0.04570970328789094, Gamma: 0.2, C:10
Gaussian Naive Bayes Classifier: Test error: 0.0946271050521251
-------Normal test resultados-------
Intervalo Naive Bayes: 57.64736622818636 a 90.35263377181364
Intervalo SVM: 39.037507822356865 a 66.96249217764314
Intervalo Gaussian Naive Bayes: 97.74133517328086 a 138.25866482671913
Os classificadores Naive Bayes e SVM não apresentam diferenças significativas, pelo que podem ter performances semelhantes (sobreposição dos intervalos)
O classificador Naive Bayes aparenta ter melhor performance que o classificador Gaussian Naive Bayes
O classificador SVM aparenta ter melhor performance que o classificador Gaussian Naive Bayes
-------McNemar test resultados-------
Test McNemar entre Naive Bayes e SVM: 7.2727272727272725
O classificador SVM aparenta ter melhor performance que o classificador Naive Bayes
Test McNemar entre Naive Bayes e Gaussian Naive Bayes: 34.24074074074074 (>=3.84)
O classificador Naive Bayes aparenta ter melhor performance que o classificador Gaussian Naive Bayes
Test McNemar entre Gaussian Naive Bayes e SVM: 39.00952380952381 (>=3.84)
O classificador SVM aparenta ter melhor performance que o classificador Gaussian Naive Bayes
Test McNemar entre SVM e SVM otimizado: 1.125 (>=3.84)
Os classificadores SVM e SVM otimizado não apresentam diferenças significativas, pelo que podem ter performances semelhantes


Q10: (Opcional) Mostre a estimativa do erro verdadeiro do classificador SVM optimizado (se fez a parte opcional do trabalho) e discuta se valeu a pena fazer essa optimização. Se não fez a parte opcional do trabalho deixe esta resposta em branco.
R10:
SVM Classifier with C: Test error: 0.04570970328789094, Gamma: 0.2, C:10
A otimização do valor C no SVM aparenta não ter valido a pena, dado que não foram obtidas melhorias comparativamente ao classificador SVM com apenas o gamma ajustado.
Foi realizado o teste McNemar para comparar os dois classificadores e foram obtidos os seguintes resultados:
Test McNemar entre SVM e SVM otimizado: 1.125
Os classificadores SVM e SVM otimizado não apresentam diferenças significativas, pelo que podem ter performances semelhantes

